{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据总数 20581\n",
      "neu 14288 0.6942325445799524\n",
      "neg 1527 0.07419464554686361\n",
      "pos 4766 0.23157280987318402\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import jieba.posseg as pseg\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def read_train(f_train,f_label):\n",
    "    labels=pd.read_csv(f_label,sep='\\t')\n",
    "    train_data=pd.read_csv(f_train,sep='\\t')\n",
    "    data=pd.merge(labels,train_data,how='left',on='SentenceId')\n",
    "    return data[data.Content.notnull()].reset_index(drop=True)\n",
    "\n",
    "train_d1=read_train('data/CarReview1.csv','data/CarAspect1.csv')\n",
    "train_d2=read_train('data/CarReview2.csv','data/CarAspect2.csv')\n",
    "# 去除视角不在原句中的\n",
    "has_view=[]\n",
    "for i in range(len(train_d1)):\n",
    "    if train_d1.loc[i,'View'] not in train_d1.loc[i,'Content']:\n",
    "        has_view.append(False)\n",
    "    else:\n",
    "        has_view.append(True)\n",
    "\n",
    "train_d1=train_d1[has_view].reset_index(drop=True)\n",
    "train_data=pd.concat([train_d1,train_d2],ignore_index=True)\n",
    "\n",
    "print('训练集数据总数',len(train_data))\n",
    "vals=Counter(train_data.Opinion.tolist())\n",
    "for key in vals:\n",
    "    print(key,vals[key],vals[key]/len(train_data))\n",
    "data=train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 样本扩展完毕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Left']=pd.Series(name='Left',index=data.index,data=['' for _ in range(len(data))])\n",
    "data['Right']=pd.Series(name='Right',index=data.index,data=['' for _ in range(len(data))])\n",
    "\n",
    "for i in range(len(data)):\n",
    "    content=data.loc[i,'Content']\n",
    "    index=content.find(data.loc[i,'View'])\n",
    "    if index<0:\n",
    "        print(data.loc[i,'SentenceId'])\n",
    "    data.set_value(i,'Left',content[:index])\n",
    "    data.set_value(i,'Right',content[index+len(data.loc[i,'View']):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.901 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词处理...\n"
     ]
    }
   ],
   "source": [
    "views=pd.read_csv('data/CarAspectDict.csv',header=None)[0].tolist()\n",
    "'''自定义词典\n",
    "'''\n",
    "for word in views:\n",
    "    for w in word.split(' '):\n",
    "        if len(w)>0:\n",
    "            jieba.add_word(w,tag='nz')\n",
    "'''分词\n",
    "'''\n",
    "print('分词处理...')\n",
    "\n",
    "data['LeftWords']=data['Left'].apply(lambda x:pseg.lcut(x))\n",
    "data['RightWords']=data['Right'].apply(lambda x:pseg.lcut(x))\n",
    "data['ViewWords']=data['View'].apply(lambda x:pseg.lcut(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "w2v_model=Word2Vec.load('data/car100_v2.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''生成词表\n",
    "'''\n",
    "vocs={}\n",
    "id2words=['']\n",
    "word_dim=w2v_model.vector_size\n",
    "w2v=[np.zeros((word_dim,))]\n",
    "\n",
    "def get_sentence_vector(w2v_model,words,i,default_dim,random=False):\n",
    "    '''传入word2vec模型以及词序列\n",
    "    返回窗口内的平均向量\n",
    "    返回句子中平均词向量，用来填充缺失的词向量\n",
    "    '''\n",
    "    if random:\n",
    "        return np.random.uniform(low=-0.01,high=0.01,size=(default_dim,))\n",
    "    else:\n",
    "        window_size=5\n",
    "        start=max(0,i-window_size)\n",
    "        end=min(i+window_size,len(words))\n",
    "        vectors=[w2v_model[w] for w in words[start:end] if w in w2v_model]\n",
    "        if len(vectors)==0:\n",
    "            return np.random.uniform(low=-0.01,high=0.01,size=(default_dim,))\n",
    "        return np.average(vectors,axis=0)\n",
    "\n",
    "def get_wids(words):\n",
    "    '''获得评价内容中词语的Id\n",
    "    '''\n",
    "    wids=[]\n",
    "    for i,word in enumerate(words):\n",
    "        w=word.word\n",
    "        if w not in vocs:\n",
    "            vocs[w]=len(vocs)+1\n",
    "            id2words.append(w)\n",
    "            if w not in w2v_model:\n",
    "                sen_vector=get_sentence_vector(w2v_model,words,i,word_dim)\n",
    "                w2v.append(sen_vector)\n",
    "            else:\n",
    "                w2v.append(w2v_model[w])\n",
    "            \n",
    "        wids.append(vocs[w])\n",
    "    return wids\n",
    "data.loc[:,'LeftIds']=data.LeftWords.apply(lambda x:get_wids(x))\n",
    "data.loc[:,'RightIds']=data.RightWords.apply(lambda x:get_wids(x))\n",
    "data.loc[:,'ViewIds']=data.ViewWords.apply(lambda x:get_wids(x))\n",
    "\n",
    "w2v=np.array(w2v,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''保存处理好的训练数据到文件中\n",
    "'''\n",
    "import pickle\n",
    "pickle.dump([data,vocs,id2words,w2v],open('data/car_review_data.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
